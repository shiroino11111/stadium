{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1382, 14)\n",
      "(154, 14)\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[4]\ttrain's l1: 0.141961\ttrain's l2: 0.0292449\ttrain's rmse: 0.171011\ttest's l1: 0.15103\ttest's l2: 0.032701\ttest's rmse: 0.180834\n",
      "[8]\ttrain's l1: 0.119457\ttrain's l2: 0.0211136\ttrain's rmse: 0.145305\ttest's l1: 0.128575\ttest's l2: 0.0246948\ttest's rmse: 0.157146\n",
      "[12]\ttrain's l1: 0.105476\ttrain's l2: 0.0168727\ttrain's rmse: 0.129895\ttest's l1: 0.114629\ttest's l2: 0.0205599\ttest's rmse: 0.143387\n",
      "[16]\ttrain's l1: 0.0967095\ttrain's l2: 0.0143513\ttrain's rmse: 0.119797\ttest's l1: 0.105898\ttest's l2: 0.0182616\ttest's rmse: 0.135135\n",
      "[20]\ttrain's l1: 0.0902499\ttrain's l2: 0.0126994\ttrain's rmse: 0.112692\ttest's l1: 0.0997593\ttest's l2: 0.0165442\ttest's rmse: 0.128624\n",
      "[24]\ttrain's l1: 0.0852231\ttrain's l2: 0.0114816\ttrain's rmse: 0.107152\ttest's l1: 0.0951393\ttest's l2: 0.015307\ttest's rmse: 0.123721\n",
      "[28]\ttrain's l1: 0.0815788\ttrain's l2: 0.0105736\ttrain's rmse: 0.102828\ttest's l1: 0.0914074\ttest's l2: 0.0143057\ttest's rmse: 0.119607\n",
      "[32]\ttrain's l1: 0.0782323\ttrain's l2: 0.0098725\ttrain's rmse: 0.0993605\ttest's l1: 0.0887262\ttest's l2: 0.0136677\ttest's rmse: 0.116909\n",
      "[36]\ttrain's l1: 0.0755676\ttrain's l2: 0.00928075\ttrain's rmse: 0.0963367\ttest's l1: 0.086491\ttest's l2: 0.0130422\ttest's rmse: 0.114202\n",
      "[40]\ttrain's l1: 0.0734087\ttrain's l2: 0.00882143\ttrain's rmse: 0.0939224\ttest's l1: 0.0846461\ttest's l2: 0.0126298\ttest's rmse: 0.112382\n",
      "[44]\ttrain's l1: 0.0715683\ttrain's l2: 0.00842697\ttrain's rmse: 0.0917985\ttest's l1: 0.0828369\ttest's l2: 0.0121754\ttest's rmse: 0.110342\n",
      "[48]\ttrain's l1: 0.0701444\ttrain's l2: 0.00810765\ttrain's rmse: 0.0900425\ttest's l1: 0.0812063\ttest's l2: 0.0117989\ttest's rmse: 0.108623\n",
      "[52]\ttrain's l1: 0.0688299\ttrain's l2: 0.00784303\ttrain's rmse: 0.0885609\ttest's l1: 0.0796389\ttest's l2: 0.0114341\ttest's rmse: 0.10693\n",
      "[56]\ttrain's l1: 0.0675737\ttrain's l2: 0.00762086\ttrain's rmse: 0.0872975\ttest's l1: 0.0787412\ttest's l2: 0.0112036\ttest's rmse: 0.105847\n",
      "[60]\ttrain's l1: 0.0666351\ttrain's l2: 0.00743058\ttrain's rmse: 0.0862008\ttest's l1: 0.0781824\ttest's l2: 0.0110242\ttest's rmse: 0.104996\n",
      "[64]\ttrain's l1: 0.0656997\ttrain's l2: 0.00723573\ttrain's rmse: 0.0850631\ttest's l1: 0.0774397\ttest's l2: 0.0108291\ttest's rmse: 0.104063\n",
      "[68]\ttrain's l1: 0.0646406\ttrain's l2: 0.0070089\ttrain's rmse: 0.0837192\ttest's l1: 0.0767479\ttest's l2: 0.0106432\ttest's rmse: 0.103166\n",
      "[72]\ttrain's l1: 0.0638006\ttrain's l2: 0.00685039\ttrain's rmse: 0.0827671\ttest's l1: 0.0762039\ttest's l2: 0.0104718\ttest's rmse: 0.102332\n",
      "[76]\ttrain's l1: 0.0629829\ttrain's l2: 0.00667993\ttrain's rmse: 0.0817309\ttest's l1: 0.0755875\ttest's l2: 0.0103069\ttest's rmse: 0.101523\n",
      "[80]\ttrain's l1: 0.0622838\ttrain's l2: 0.0065607\ttrain's rmse: 0.0809981\ttest's l1: 0.0750755\ttest's l2: 0.0101708\ttest's rmse: 0.10085\n",
      "[84]\ttrain's l1: 0.0616042\ttrain's l2: 0.00643766\ttrain's rmse: 0.080235\ttest's l1: 0.0746021\ttest's l2: 0.0100348\ttest's rmse: 0.100174\n",
      "[88]\ttrain's l1: 0.0609093\ttrain's l2: 0.0063231\ttrain's rmse: 0.0795179\ttest's l1: 0.0740251\ttest's l2: 0.00992283\ttest's rmse: 0.0996134\n",
      "[92]\ttrain's l1: 0.0601097\ttrain's l2: 0.0061536\ttrain's rmse: 0.0784449\ttest's l1: 0.073461\ttest's l2: 0.00979664\ttest's rmse: 0.098978\n",
      "[96]\ttrain's l1: 0.0594385\ttrain's l2: 0.00600243\ttrain's rmse: 0.0774753\ttest's l1: 0.0730211\ttest's l2: 0.00972439\ttest's rmse: 0.0986123\n",
      "[100]\ttrain's l1: 0.0588478\ttrain's l2: 0.00587335\ttrain's rmse: 0.0766378\ttest's l1: 0.0731958\ttest's l2: 0.00965721\ttest's rmse: 0.0982711\n",
      "[104]\ttrain's l1: 0.0582008\ttrain's l2: 0.00576674\ttrain's rmse: 0.0759391\ttest's l1: 0.0731877\ttest's l2: 0.00963963\ttest's rmse: 0.0981816\n",
      "[108]\ttrain's l1: 0.0576345\ttrain's l2: 0.00567795\ttrain's rmse: 0.0753522\ttest's l1: 0.0730847\ttest's l2: 0.00963313\ttest's rmse: 0.0981485\n",
      "[112]\ttrain's l1: 0.0570714\ttrain's l2: 0.00557973\ttrain's rmse: 0.0746976\ttest's l1: 0.0731356\ttest's l2: 0.00960917\ttest's rmse: 0.0980264\n",
      "[116]\ttrain's l1: 0.0563837\ttrain's l2: 0.00545784\ttrain's rmse: 0.0738772\ttest's l1: 0.0727133\ttest's l2: 0.00949626\ttest's rmse: 0.0974488\n",
      "[120]\ttrain's l1: 0.0559034\ttrain's l2: 0.00536021\ttrain's rmse: 0.0732135\ttest's l1: 0.0730356\ttest's l2: 0.00950275\ttest's rmse: 0.097482\n",
      "[124]\ttrain's l1: 0.055411\ttrain's l2: 0.00526534\ttrain's rmse: 0.0725627\ttest's l1: 0.0726109\ttest's l2: 0.0094244\ttest's rmse: 0.0970793\n",
      "[128]\ttrain's l1: 0.0549586\ttrain's l2: 0.0051869\ttrain's rmse: 0.0720202\ttest's l1: 0.0723683\ttest's l2: 0.00936479\ttest's rmse: 0.0967718\n",
      "[132]\ttrain's l1: 0.0545601\ttrain's l2: 0.00511776\ttrain's rmse: 0.0715385\ttest's l1: 0.0721242\ttest's l2: 0.00931979\ttest's rmse: 0.0965391\n",
      "[136]\ttrain's l1: 0.0540724\ttrain's l2: 0.0050407\ttrain's rmse: 0.0709979\ttest's l1: 0.0719852\ttest's l2: 0.00928922\ttest's rmse: 0.0963806\n",
      "[140]\ttrain's l1: 0.0535641\ttrain's l2: 0.00495894\ttrain's rmse: 0.0704198\ttest's l1: 0.071852\ttest's l2: 0.00924391\ttest's rmse: 0.0961452\n",
      "[144]\ttrain's l1: 0.0532037\ttrain's l2: 0.00490261\ttrain's rmse: 0.0700187\ttest's l1: 0.0715295\ttest's l2: 0.00920986\ttest's rmse: 0.095968\n",
      "[148]\ttrain's l1: 0.0527761\ttrain's l2: 0.00483099\ttrain's rmse: 0.0695053\ttest's l1: 0.0717315\ttest's l2: 0.00922866\ttest's rmse: 0.0960659\n",
      "[152]\ttrain's l1: 0.0523629\ttrain's l2: 0.0047684\ttrain's rmse: 0.0690536\ttest's l1: 0.0717804\ttest's l2: 0.00926582\ttest's rmse: 0.0962591\n",
      "[156]\ttrain's l1: 0.0518935\ttrain's l2: 0.00469603\ttrain's rmse: 0.0685276\ttest's l1: 0.0716\ttest's l2: 0.00920142\ttest's rmse: 0.095924\n",
      "[160]\ttrain's l1: 0.0515232\ttrain's l2: 0.00463827\ttrain's rmse: 0.0681049\ttest's l1: 0.0715433\ttest's l2: 0.00921145\ttest's rmse: 0.0959763\n",
      "[164]\ttrain's l1: 0.0511877\ttrain's l2: 0.00457932\ttrain's rmse: 0.0676707\ttest's l1: 0.0717086\ttest's l2: 0.00923947\ttest's rmse: 0.0961222\n",
      "[168]\ttrain's l1: 0.0508412\ttrain's l2: 0.00452044\ttrain's rmse: 0.0672342\ttest's l1: 0.0716546\ttest's l2: 0.00922457\ttest's rmse: 0.0960446\n",
      "[172]\ttrain's l1: 0.050488\ttrain's l2: 0.00446425\ttrain's rmse: 0.066815\ttest's l1: 0.0715432\ttest's l2: 0.00921182\ttest's rmse: 0.0959782\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttrain's l1: 0.0517115\ttrain's l2: 0.00466708\ttrain's rmse: 0.0683161\ttest's l1: 0.0713799\ttest's l2: 0.00918642\ttest's rmse: 0.0958458\n",
      "rmse : 3336.806378848174\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import calc_lightgbm\n",
    "\n",
    "def read_df():\n",
    "    df_train = pd.read_csv('data/train.csv', encoding='utf-8')\n",
    "    df_train_add = pd.read_csv('data/train_add.csv', encoding='utf-8')\n",
    "    df_studium = pd.read_csv('data/stadium.csv', encoding='utf-8')\n",
    "    df_condition = pd.read_csv('data/condition.csv', encoding='utf-8')\n",
    "    df_condition_add = pd.read_csv('data/condition_add.csv', encoding='utf-8')\n",
    "\n",
    "    # add_dataの統合\n",
    "    df_train_concat = pd.concat([df_train, df_train_add])\n",
    "    df_condition_concat =  pd.concat([df_condition, df_condition_add])\n",
    "\n",
    "    #trainとconditionをmerge\n",
    "    df = pd.merge(df_train_concat, df_condition_concat, on=\"id\")\n",
    "\n",
    "    #更にスタジアムをマージ\n",
    "    df = pd.merge(df, df_studium, left_on=\"stadium\", right_on='name')\n",
    "\n",
    "    # ダブり変数、審判、選手、スコア削除\n",
    "    df1 = df.loc[:, ['id', 'y', 'year', 'stage', 'match', 'gameday', 'time', 'home', 'away', 'stadium', 'tv', 'home_score', 'away_score', 'weather', 'temperature',\n",
    "                     'humidity', 'capa']]\n",
    "\n",
    "    #### カテゴリカル変数の数値化\n",
    "    # ザスパの名前を統一\n",
    "    df1['home'].replace(['ザスパ草津'], ['ザスパクサツ群馬'], inplace=True)\n",
    "    df1['away'].replace(['ザスパ草津'], ['ザスパクサツ群馬'], inplace=True)\n",
    "\n",
    "    # timeを時間だけにする\n",
    "    df1['time'] = df1['time'].str[:2].astype('int64')\n",
    "\n",
    "    # matchを節と日にわける。\n",
    "    df1['match_sec'] = df1['match'].str[1:-4].astype('int64').astype('int64')\n",
    "    df1['match_sec_day'] = df1['match'].str[-2:-1].astype('int64')\n",
    "\n",
    "    # 月の特徴量\n",
    "    df1['month'] = df1['gameday'].str[:2].astype('int64')\n",
    "\n",
    "    # 曜日の特徴量\n",
    "    df1['weekday'] =  df1['gameday'].str[6]\n",
    "\n",
    "    # 祝日かどうか\n",
    "    df1.loc[df1['gameday'].str.len() < 9, 'holiday'] = 0\n",
    "    df1.loc[df1['gameday'].str.len() >= 9, 'holiday'] = 1\n",
    "\n",
    "    # humidlyを数値に\n",
    "    df1['humidity'] = df1['humidity'].str[:2].astype('int64')\n",
    "    \n",
    "    return df1\n",
    "\n",
    "#### 距離関連の特徴量作成\n",
    "def team_latlon(team_x):\n",
    "    # チームの緯度と経度\n",
    "    df_team_latlon = pd.read_csv('data/team_latlon.csv', encoding='ANSI')\n",
    "    dict_team_lat = dict(zip(df_team_latlon['team'], df_team_latlon['latitude']))\n",
    "    dict_team_lon = dict(zip(df_team_latlon['team'], df_team_latlon['longitude']))\n",
    "        \n",
    "    return pd.Series([dict_team_lat.get(team_x), dict_team_lon.get(team_x)])\n",
    "\n",
    "\n",
    "def add_distance(df1):\n",
    "    def studium_latlon(studium_x):\n",
    "        # スタジアムの緯度と経度\n",
    "        return pd.Series([dict_studium_lat.get(studium_x), dict_studium_lon.get(studium_x)])\n",
    "\n",
    "\n",
    "    def check_home_studium(df_x):\n",
    "        # ホームチームがホームスタジアムで試合をしたか確認\n",
    "        # ホームスタジアムでの試合なら０を返す\n",
    "        if dict_stadium.get(df_x['stadium']) == df_x['home']:\n",
    "            return 0\n",
    "        # 横浜ＦＣがニッパツ三ツ沢球技場での試合なら０を返す\n",
    "        elif df_x['stadium'] == 'ニッパツ三ツ沢球技場' and df_x['home'] == '横浜ＦＣ': \n",
    "            return 0\n",
    "        # 東京ヴェルディが味の素スタジアムでの試合なら０を返す\n",
    "        elif df_x['stadium'] == '味の素スタジアム' and df_x['home'] == '東京ヴェルディ': \n",
    "            return 0\n",
    "        \n",
    "        # ホームチームがホームスタジアムで試合したら０を返す\n",
    "        else: \n",
    "            return 1\n",
    "\n",
    "    # チームの緯度経度\n",
    "    df1[['home_latitude', 'home_longitude']] = df1['home'].apply(team_latlon)\n",
    "    df1[['away_latitude', 'away_longitude']] = df1['away'].apply(team_latlon)\n",
    "\n",
    "    # スタジアムの緯度経度\n",
    "    df_stadium = pd.read_csv('data/stadium_sub.csv')\n",
    "    dict_studium_lat = dict(zip(df_stadium['stadium'], df_stadium['latitude']))\n",
    "    dict_studium_lon = dict(zip(df_stadium['stadium'], df_stadium['longitude']))\n",
    "    df1[['studium_latitude', 'studium_longitude']] = df1['stadium'].apply(studium_latlon)\n",
    "\n",
    "    # なぜか鹿児島県立鴨池陸上競技場だけ緯度経度がNanになるので補完\n",
    "    df1['studium_latitude'].fillna((31.56483), inplace=True)\n",
    "    df1['studium_longitude'].fillna((130.560144), inplace=True)\n",
    "\n",
    "    # どのチームが所有するスタジアムか\n",
    "    dict_stadium = dict(zip(df_stadium['stadium'], df_stadium['team1']))\n",
    "    df1['away_game'] = df1.apply(check_home_studium, axis=1)\n",
    "\n",
    "    # スタジアムとの距離\n",
    "    distance_home = []\n",
    "    distance_away = []\n",
    "\n",
    "    for row in range(len(df1.index)):\n",
    "        studium_lat_lon = (df1.loc[row, 'studium_latitude'], df1.loc[row, 'studium_longitude'])\n",
    "        away_lat_lon = (df1.loc[row, 'away_latitude'], df1.loc[row, 'away_longitude'])\n",
    "        dist_away = distance.euclidean(away_lat_lon, studium_lat_lon)\n",
    "        distance_away.append(dist_away)\n",
    "        \n",
    "        if df1.loc[row,'away_game'] == 0:\n",
    "            # haway_gameが0のときは、0\n",
    "            # それ以外の時は、距離計算。\n",
    "            distance_home.append(0)\n",
    "        \n",
    "        else:\n",
    "            home_lat_lon = (df1.loc[row, 'home_latitude'], df1.loc[row, 'home_longitude'])\n",
    "            dist_home = distance.euclidean(home_lat_lon, studium_lat_lon)\n",
    "            distance_home.append(dist_home)\n",
    "        \n",
    "        \n",
    "    df1['distance_home'] = pd.Series(distance_home)\n",
    "    df1['distance_away'] = pd.Series(distance_away)\n",
    "    \n",
    "    return df1\n",
    "\n",
    "\n",
    "def add_win_lose_point(df1):\n",
    "    # 各試合のhome勝ち点欄、away勝ち点欄挿入\n",
    "    # 勝利3点、引き分け1点、敗戦0点\n",
    "\n",
    "    home_points=[]\n",
    "    away_points=[]\n",
    "\n",
    "\n",
    "    for c in range(len(df1.index)):\n",
    "        if df1.loc[c,'away_score'] > df1.loc[c,'home_score']:\n",
    "            home_points.append(0)\n",
    "            away_points.append(3)\n",
    "\n",
    "        elif df1.loc[c,'away_score'] == df1.loc[c,'home_score']:\n",
    "            home_points.append(1)\n",
    "            away_points.append(1)\n",
    "\n",
    "        else:\n",
    "            home_points.append(3)\n",
    "            away_points.append(0)\n",
    "        \n",
    "        \n",
    "    df1['points_home'] = pd.Series(home_points)\n",
    "    df1['points_away'] = pd.Series(away_points)\n",
    "\n",
    "    # アウェイチームの直近5試合の勝ち点平均特徴量挿入\n",
    "\n",
    "    point_5game_average_away=[                (\n",
    "                # ホーム試合の勝ち点合計\n",
    "                df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-1) & (df1['year'] == df1.loc[i,'year']) & (df1['home'] == df1.loc[c,'away']), 'points_home'].sum()\\\n",
    "                +df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-2) & (df1['year'] == df1.loc[i,'year']) & (df1['home'] == df1.loc[c,'away']), 'points_home'].sum()\\\n",
    "                +df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-3) & (df1['year'] == df1.loc[i,'year']) & (df1['home'] == df1.loc[c,'away']), 'points_home'].sum()\\\n",
    "                +df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-4) & (df1['year'] == df1.loc[i,'year']) & (df1['home'] == df1.loc[c,'away']), 'points_home'].sum()\\\n",
    "                +df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-5) & (df1['year'] == df1.loc[i,'year']) & (df1['home'] == df1.loc[c,'away']), 'points_home'].sum()\\\n",
    "                +\\\n",
    "                # アウェイ試合の勝ち点合計\n",
    "                df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-1) & (df1['year'] == df1.loc[i,'year']) & (df1['away'] == df1.loc[c,'away']), 'points_away'].sum()\\\n",
    "                +df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-2) & (df1['year'] == df1.loc[i,'year']) & (df1['away'] == df1.loc[c,'away']), 'points_away'].sum()\\\n",
    "                +df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-3) & (df1['year'] == df1.loc[i,'year']) & (df1['away'] == df1.loc[c,'away']), 'points_away'].sum()\\\n",
    "                +df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-4) & (df1['year'] == df1.loc[i,'year']) & (df1['away'] == df1.loc[c,'away']), 'points_away'].sum()\\\n",
    "                +df1.loc[(df1['match_sec'] == df1.loc[i, 'match_sec']-5) & (df1['year'] == df1.loc[i,'year']) & (df1['away'] == df1.loc[c,'away']), 'points_away'].sum())\\\n",
    "                    /5\\\n",
    "                    for i in range(len(df1.index))]# 全部の行で処理\n",
    "\n",
    "    df1['point_5game_average_away'] = pd.Series(point_5game_average_away)\n",
    "    return df1\n",
    "\n",
    "def weather(df1_weather):\n",
    "    # 天候をグループ分け(df1_weather)\n",
    "    df1_weather['weather'].replace(['晴のち曇'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴のち曇一時雨'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴のち曇時々雨'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴のち雨'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴一時曇'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴一時雨'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴時々曇'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴時々雨'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴時々曇'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴時々雨'], ['やや晴'], inplace=True)\n",
    "    df1_weather['weather'].replace(['晴時々雪'], ['やや晴'], inplace=True)\n",
    "\n",
    "    df1_weather['weather'].replace(['曇のち晴'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇のち雨'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇のち雪'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇のち雷雨'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇一時晴'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇一時晴一時雨'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇一時雨'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇一時雨のち晴'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇一時雷雨のち曇'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇時々晴'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇時々晴一時雨'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇時々雨'], ['やや曇'], inplace=True)\n",
    "    df1_weather['weather'].replace(['曇時々雨のち晴'], ['やや曇'], inplace=True)\n",
    "\n",
    "    df1_weather['weather'].replace(['雨のち晴'], ['やや雨'], inplace=True)\n",
    "    df1_weather['weather'].replace(['雨のち曇'], ['やや雨'], inplace=True)\n",
    "    df1_weather['weather'].replace(['雨のち曇時々晴'], ['やや雨'], inplace=True)\n",
    "    df1_weather['weather'].replace(['雨時々晴'], ['やや雨'], inplace=True)\n",
    "    df1_weather['weather'].replace(['雨時々曇'], ['やや雨'], inplace=True)\n",
    "\n",
    "    df1_weather['weather'].replace(['雪のち雨'], ['やや雪'], inplace=True)\n",
    "\n",
    "    df1_weather = df1_weather.loc[:, [\"id\", \"weather\"]]\n",
    "    \n",
    "    return df1_weather\n",
    "\n",
    "def stadium_average(df_stadium_average):\n",
    "    # スタジアムにおける観客数平均、満員率平均の２変数をクラスタリング(df_stadium_average) \n",
    "    df_stadium_average['Occupancy_rate'] = df_stadium_average['Occupancy_rate'] = df_stadium_average['y'] / df_stadium_average['capa']\n",
    "    df_stadium_average = pd.pivot_table(df_stadium_average.query(\"year == 2012 or year == 2013\"),\n",
    "                                        index=\"stadium\", \n",
    "                                        values=[\"y\", 'Occupancy_rate'])\n",
    "\n",
    "    #分散正規化のインスタンスを作成\n",
    "    stdsc = StandardScaler()\n",
    "    #分散正規化を実行\n",
    "    stdsc.fit(df_stadium_average)\n",
    "    stdsc.transform(df_stadium_average)\n",
    "\n",
    "    max_cluster_num = 10\n",
    "    data_array_class_stadium_average = stdsc.transform(df_stadium_average)\n",
    "\n",
    "    #クラスタ分析を実行 (クラスタ数=3)\n",
    "    n_clusters=3\n",
    "    pred_stadium = KMeans(n_clusters=3, random_state=0).fit_predict(data_array_class_stadium_average)\n",
    "    df_stadium_average[\"stadium_class\"] = pred_stadium\n",
    "\n",
    "    df_stadium_average = df_stadium_average.reset_index()\n",
    "\n",
    "    #カラム変更\n",
    "    df_stadium_average = df_stadium_average.loc[:, [\"stadium\", \"stadium_class\"]]\n",
    "\n",
    "    #2012～2013のデータがない香川県立丸亀競技場を追加\n",
    "    df_stadium_average.loc[58] = [ '香川県立丸亀競技場', \"0\"]\n",
    "    df_stadium_average['stadium_class'] = df_stadium_average['stadium_class'].astype(np.int64)\n",
    "    \n",
    "    return df_stadium_average\n",
    "\n",
    "def studium_ave(df1):\n",
    "    df1_studium_ave = df1.query(\"year == 2012 or year == 2013\")\n",
    "    df1_studium_ave = pd.pivot_table(df1_studium_ave, index=\"stadium\", values=\"y\")\n",
    "    df1_studium_ave = df1_studium_ave.reset_index()\n",
    "    df1_studium_ave = df1_studium_ave.rename({\"y\":\"stadium_average\"}, axis=1)\n",
    "    return df1_studium_ave\n",
    "\n",
    "def add_finance(df1):\n",
    "    #財務関係の特徴量を挿入(\n",
    "    df_finance = pd.read_csv('data/Jleague基礎データ.csv', encoding='ANSI')\n",
    "\n",
    "    year2012 = df1.query('year == 2012')\n",
    "    year2013 = df1.query('year == 2013')\n",
    "    year2014 = df1.query('year == 2014')\n",
    "\n",
    "    #前年度財務\n",
    "    df_finance2011 = df_finance[['name', '2011営業収入', '2011入場料', '2011スポンサー料', '2011人件費', '2012home', '2012away']]\n",
    "    df_finance2012 = df_finance[['name', '2012営業収入', '2012入場料', '2012スポンサー料', '2012人件費', '2013home', '2013away']]\n",
    "    df_finance2013 = df_finance[['name', '2013営業収入', '2013入場料', '2013スポンサー料', '2013人件費', '2014home', '2014away']]\n",
    "\n",
    "    #財務関係カラム名変更\n",
    "    df_finance2011= df_finance2011.rename(columns={'2011営業収入':'last_year_income', \n",
    "                                                   '2011入場料':'last_year_entrancefee',\n",
    "                                                   '2011スポンサー料':'last_year_Sponsorfee',\n",
    "                                                   '2011人件費':'last_year_laborcost',\n",
    "                                                   '2012home':'home_avarage',\n",
    "                                                   '2012away':'away_avarage'})\n",
    "    df_finance2012 =df_finance2012.rename(columns={'2012営業収入':'last_year_income',\n",
    "                                                   '2012入場料':'last_year_entrancefee',\n",
    "                                                   '2012スポンサー料':'last_year_Sponsorfee',\n",
    "                                                   '2012人件費':'last_year_laborcost',\n",
    "                                                   '2013home':'home_avarage',\n",
    "                                                   '2013away':'away_avarage'})\n",
    "    df_finance2013 =df_finance2013.rename(columns={'2013営業収入':'last_year_income',\n",
    "                                                   '2013入場料':'last_year_entrancefee',\n",
    "                                                   '2013スポンサー料':'last_year_Sponsorfee',\n",
    "                                                   '2013人件費':'last_year_laborcost',\n",
    "                                                   '2014home':'home_avarage',\n",
    "                                                   '2014away':'away_avarage'})\n",
    "\n",
    "    #3パターンの年度データとその前年度財務データをマージ\n",
    "    year2012_finance = pd.merge(year2012, df_finance2011, left_on='home', right_on='name')\n",
    "    year2012_finance  = pd.merge(year2012_finance, df_finance2011, left_on='away', right_on='name')\n",
    "\n",
    "    year2013_finance = pd.merge(year2013,df_finance2012, left_on='home', right_on='name')\n",
    "    year2013_finance = pd.merge(year2013_finance, df_finance2012, left_on='away', right_on='name')\n",
    "\n",
    "    year2014_finance = pd.merge(year2014, df_finance2013, left_on='home', right_on='name')\n",
    "    year2014_finance = pd.merge(year2014_finance, df_finance2013, left_on='away', right_on='name')\n",
    "\n",
    "    #2012,2013,2014を縦に結合\n",
    "    df_finance_add = pd.concat([year2012_finance, year2013_finance, year2014_finance], axis=0)\n",
    "    #不要なカラム\"name_x\"と\"name_y\"を削除\n",
    "    df_finance_add = df_finance_add.drop(['name_x', 'name_y'], axis=1)\n",
    "    #カラム名変更\n",
    "    df_finance_add = (df_finance_add.rename({\"last_year_income_x\":\"last_year_income_home\",\n",
    "                                             \"last_year_entrancefee_x\":\"last_year_entrancefee_home\",\n",
    "                                             \"last_year_Sponsorfee_x\":\"last_year_Sponsorfee_home\",\n",
    "                                             \"last_year_laborcost_x\":\"last_year_laborcost_home\",\n",
    "                                             \"home_avarage_x\":\"hometeam_home_avarage\",\n",
    "                                             \"away_avarage_x\":\"hometeam_away_avarage\",\n",
    "                                             \"last_year_income_y\":\"last_year_income_away\",\n",
    "                                             \"last_year_entrancefee_y\":\"last_year_entrancefee_away\",\n",
    "                                             \"last_year_Sponsorfee_y\":\"last_year_Sponsorfee_away\",\n",
    "                                             \"last_year_laborcost_y\":\"last_year_laborcost_away\",\n",
    "                                             \"home_avarage_y\":\"awayteam_home_avarage\",\n",
    "                                             \"away_avarage_y\":\"awayteam_away_avarage\"},\n",
    "                                            axis=1))\n",
    "    return df_finance_add\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    df1 = read_df()\n",
    "    #### 距離関連の特徴量作成\n",
    "    df1 = add_distance(df1)\n",
    "\n",
    "    # 各試合のhome勝ち点欄、away勝ち点欄挿入\n",
    "    df1 = add_win_lose_point(df1)\n",
    "\n",
    "    # 天候をグループ分け\n",
    "    df1_weather = weather(df1)\n",
    "\n",
    "    # スタジアムにおける観客数平均、満員率平均の２変数をクラスタリング(df_stadium_average)\n",
    "    df_stadium_average = stadium_average(df1)\n",
    "\n",
    "    # スタジアム別平均観客動員数(df1_studium_ave)\n",
    "    df1_studium_ave = studium_ave(df1)\n",
    "\n",
    "    df1 = add_finance(df1)\n",
    "\n",
    "    #df1と天気とクラスタリングととスタジアム別平均観客動員数をマージして、新たなdf1_mergeとする\n",
    "    df_stadium= pd.merge(df1, df1_studium_ave, on=\"stadium\", how=\"outer\")\n",
    "    df_weather = pd.merge(df_stadium, df1_weather, on=\"id\")\n",
    "    df_stadium_class = pd.merge(df_weather, df_stadium_average, on=\"stadium\")\n",
    "    df1_merge = df_stadium_class\n",
    "\n",
    "    calc_lightgbm.main(df1_merge)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
